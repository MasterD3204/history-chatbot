import streamlit as st
from typing import Dict, Any

# Import RAG chain Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng hoÃ n chá»‰nh tá»« module cá»§a báº¡n
from chain import rag_chain
# Import LLM_MAP Ä‘á»ƒ láº¥y danh sÃ¡ch cÃ¡c model cho ngÆ°á»i dÃ¹ng chá»n
from llm_handle import LLM_MAP

# --- 1. Cáº¤U HÃŒNH TRANG VÃ€ TIÃŠU Äá»€ ---

# st.set_page_config Ä‘á»ƒ Ä‘áº·t tiÃªu Ä‘á» vÃ  icon cho tab trÃ¬nh duyá»‡t
st.set_page_config(page_title="Chatbot Lá»‹ch sá»­", page_icon="ğŸ“œ")

# st.title Ä‘á»ƒ hiá»ƒn thá»‹ tiÃªu Ä‘á» chÃ­nh trÃªn trang
st.title("ğŸ“œ Chatbot Lá»‹ch sá»­ Viá»‡t Nam")
st.caption("Cung cáº¥p bá»Ÿi cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ tiÃªn tiáº¿n")

# --- 2. Cáº¤U HÃŒNH THANH BÃŠN (SIDEBAR) ---

# st.sidebar cho phÃ©p táº¡o má»™t thanh cÃ´ng cá»¥ bÃªn cáº¡nh
with st.sidebar:
    st.header("Cáº¥u hÃ¬nh")

    # Táº¡o má»™t dropdown (selectbox) Ä‘á»ƒ ngÆ°á»i dÃ¹ng chá»n model
    # LLM_MAP.keys() sáº½ láº¥y ra cÃ¡c lá»±a chá»n: "gemini", "openai", "default"
    selected_model = st.selectbox(
        label="Chá»n mÃ´ hÃ¬nh LLM",
        options=list(LLM_MAP.keys()),
        index=0  # Máº·c Ä‘á»‹nh chá»n model Ä‘áº§u tiÃªn trong danh sÃ¡ch
    )

    # Táº¡o má»™t thanh trÆ°á»£t (slider) Ä‘á»ƒ Ä‘iá»u chá»‰nh nhiá»‡t Ä‘á»™ (temperature)
    # temperature = st.slider(
    #     label="Má»©c Ä‘á»™ sÃ¡ng táº¡o (Temperature)",
    #     min_value=0.0,
    #     max_value=1.0,
    #     value=0.5, # GiÃ¡ trá»‹ máº·c Ä‘á»‹nh
    #     step=0.1
    # )
    
    st.info("LÆ°u Ã½: Thay Ä‘á»•i mÃ´ hÃ¬nh hoáº·c cáº¥u hÃ¬nh sáº½ Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¢u há»i tiáº¿p theo.")


# --- 3. KHá»I Táº O Lá»ŠCH Sá»¬ CHAT ---

# Sá»­ dá»¥ng st.session_state Ä‘á»ƒ lÆ°u trá»¯ tin nháº¯n giá»¯a cÃ¡c láº§n cháº¡y láº¡i
# Äiá»u nÃ y ráº¥t quan trá»ng Ä‘á»ƒ duy trÃ¬ cuá»™c trÃ² chuyá»‡n
if "messages" not in st.session_state:
    st.session_state.messages = [
        # Tin nháº¯n chÃ o má»«ng ban Ä‘áº§u tá»« trá»£ lÃ½
        {"role": "assistant", "content": "Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n vá» lá»‹ch sá»­ Viá»‡t Nam?"}
    ]

# --- 4. HIá»‚N THá»Š CÃC TIN NHáº®N CÅ¨ ---

# Láº·p qua danh sÃ¡ch tin nháº¯n Ä‘Ã£ lÆ°u vÃ  hiá»ƒn thá»‹ chÃºng
for message in st.session_state.messages:
    # st.chat_message táº¡o má»™t container cho tin nháº¯n vá»›i avatar tÆ°Æ¡ng á»©ng
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 5. Xá»¬ LÃ NHáº¬P LIá»†U Má»šI Tá»ª NGÆ¯á»œI DÃ™NG ---

# st.chat_input táº¡o má»™t Ã´ nháº­p liá»‡u cá»‘ Ä‘á»‹nh á»Ÿ cuá»‘i trang
if user_prompt := st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n..."):

    # 5.1. LÆ°u vÃ  hiá»ƒn thá»‹ cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user"):
        st.markdown(user_prompt)

    # 5.2. Táº¡o vÃ  hiá»ƒn thá»‹ pháº£n há»“i tá»« LLM
    with st.chat_message("assistant"):
        # st.spinner táº¡o ra hiá»‡u á»©ng chá» (animation) vá»›i thÃ´ng bÃ¡o
        with st.spinner("Äang suy nghÄ©..."):
            
            # Chuáº©n bá»‹ input cho RAG chain
            # Bao gá»“m cÃ¢u há»i, lá»±a chá»n model vÃ  cÃ¡c cáº¥u hÃ¬nh khÃ¡c
            input_data: Dict[str, Any] = {
                "question": user_prompt,
                "llm_choice": selected_model
            }

            # Gá»i RAG chain Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i
            response = rag_chain.invoke(input_data)
            
            # Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i
            st.markdown(response)

    # 5.3. LÆ°u láº¡i cÃ¢u tráº£ lá»i cá»§a trá»£ lÃ½ vÃ o lá»‹ch sá»­ chat
    st.session_state.messages.append({"role": "assistant", "content": response})